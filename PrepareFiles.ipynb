{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifying faces using Convolutional neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convolutional neural networks are routinely used to classify images. Here's a rudimentary workflow that can be used to classify faces. In this notebook, the images obtained from this challenge were used to classify them into three categories according to their ages.\n",
    "The dataset consists of images of people labelled with their ages. The typical images are frontal shots which contain the face of the person. Since we plan to classify images according to facial features, we isolate and crop out the image of the face and store it on the disk as a separate png file. These files are then used to train the network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. DATASET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset consists of 2476 labelled images from the CHALearn \"Looking at people\" dataset for the [\"Apparent age V2 (CVPR '16)\" challenge](http://chalearnlap.cvc.uab.es/dataset/19/description/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4112 entries, 0 to 4111\n",
      "Data columns (total 3 columns):\n",
      "Filename    4112 non-null object\n",
      "Age         4112 non-null float32\n",
      "Std         4112 non-null float32\n",
      "dtypes: float32(2), object(1)\n",
      "memory usage: 64.4+ KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f93c62d78d0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "labels=pd.read_csv('train_gt.csv',sep=',',header=1,names=['Filename','Age','Std'], dtype={'Filename':str , 'Age':np.float32 , 'Std':np.float32 }  )\n",
    "#labels['Age_category'],agebins=pd.qcut(labels['Age'],3,labels=False,retbins=True)\n",
    "print(labels.info())\n",
    "labels['Age'].hist(bins=np.arange(0,90,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's filter out the faces of adults since those look significantly similar than the children/teenagers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 3486 entries, 0 to 4111\n",
      "Data columns (total 3 columns):\n",
      "Filename    3486 non-null object\n",
      "Age         3486 non-null float32\n",
      "Std         3486 non-null float32\n",
      "dtypes: float32(2), object(1)\n",
      "memory usage: 81.7+ KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f93c615f908>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels_adults=labels.loc[labels['Age']>18.0]\n",
    "print(labels_adults.info())\n",
    "labels_adults['Age'].hist(bins=np.arange(18,90,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's sort the dataset into three equally sized groups by age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/prasadb/miniconda3/envs/tf-graphViz/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "labels_adults['Age_category'],agebins=pd.qcut(labels_adults['Age'],3,labels=False,retbins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18.04347801 26.22940254 36.25555547 89.15384674]\n"
     ]
    }
   ],
   "source": [
    "print(agebins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>Age</th>\n",
       "      <th>Std</th>\n",
       "      <th>Age_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>001060.jpg</td>\n",
       "      <td>35.462963</td>\n",
       "      <td>4.901674</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>003987.jpg</td>\n",
       "      <td>20.136364</td>\n",
       "      <td>3.671703</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>002290.jpg</td>\n",
       "      <td>68.538460</td>\n",
       "      <td>7.203440</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>001969.jpg</td>\n",
       "      <td>28.933332</td>\n",
       "      <td>6.702901</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>003617.jpg</td>\n",
       "      <td>24.928572</td>\n",
       "      <td>6.318502</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Filename        Age       Std  Age_category\n",
       "0  001060.jpg  35.462963  4.901674             1\n",
       "1  003987.jpg  20.136364  3.671703             0\n",
       "2  002290.jpg  68.538460  7.203440             2\n",
       "3  001969.jpg  28.933332  6.702901             1\n",
       "4  003617.jpg  24.928572  6.318502             0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_adults.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Cropping out the face from the images\n",
    "\n",
    "We will be using the Haar Cascade filters available in openCV to filter out the face. This filter typically identifies a few parts of the image as the face. We choose the largest such part as the face."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "cascPath=\"/home/prasadb/miniconda3/envs/tf-graphViz/lib/python3.6/site-packages/cv2/data/haarcascade_frontalface_default.xml\"\n",
    "eyePath=\"/home/prasadb/miniconda3/envs/tf-graphViz/lib/python3.6/site-packages/cv2/data/haarcascade_eye.xml\"\n",
    "smilePath=\"/home/prasadb/miniconda3/envs/tf-graphViz/lib/python3.6/site-packages/cv2/data/haarcascade_smile.xml\"\n",
    "\n",
    "faceCascade = cv2.CascadeClassifier(cascPath)\n",
    "eyeCascade = cv2.CascadeClassifier(eyePath)\n",
    "smileCascade = cv2.CascadeClassifier(smilePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcarea(a):\n",
    "    return a[2]*a[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir Faces\n",
    "!mkdir Faces/0\n",
    "!mkdir Faces/1\n",
    "!mkdir Faces/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "343 Pandas(Index=343, Filename='001538.jpg', Age=32.82352828979492, Std=6.500998020172119, Age_category=1)\n",
      "343 (480, 321)\n",
      "255\n",
      "0\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "419 Pandas(Index=419, Filename='003257.jpg', Age=27.585186004638672, Std=4.556452751159668, Age_category=1)\n",
      "419 (158, 135)\n",
      "255\n",
      "0\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "579 Pandas(Index=579, Filename='001249.jpg', Age=25.91666603088379, Std=4.462031364440918, Age_category=0)\n",
      "579 (1175, 800)\n",
      "255\n",
      "0\n",
      "--------------------------------------------------\n",
      "-----Write Error----------------------------------\n",
      "579 Pandas(Index=579, Filename='001249.jpg', Age=25.91666603088379, Std=4.462031364440918, Age_category=0)\n",
      "Faces/0/579001249.png\n",
      "(0, 0)\n",
      "--------------------------------------------------\n",
      "986 Pandas(Index=986, Filename='002201.jpg', Age=35.26315689086914, Std=4.934754371643066, Age_category=1)\n",
      "986 (758, 569)\n",
      "255\n",
      "0\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "1264 Pandas(Index=1264, Filename='001309.jpg', Age=24.538461685180664, Std=4.235661506652832, Age_category=0)\n",
      "1264 (1202, 800)\n",
      "255\n",
      "34\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "1555 Pandas(Index=1555, Filename='001836.jpg', Age=46.81081008911133, Std=5.9540486335754395, Age_category=2)\n",
      "1555 (1188, 1000)\n",
      "255\n",
      "0\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "2442 Pandas(Index=2442, Filename='001397.jpg', Age=48.30769348144531, Std=5.836023807525635, Age_category=2)\n",
      "2442 (1286, 1000)\n",
      "255\n",
      "0\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "2920 Pandas(Index=2920, Filename='002538.jpg', Age=40.5, Std=8.580501556396484, Age_category=2)\n",
      "2920 (631, 481)\n",
      "255\n",
      "35\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "3033 Pandas(Index=3033, Filename='002742.jpg', Age=59.53845977783203, Std=6.990272045135498, Age_category=2)\n",
      "3033 (540, 532)\n",
      "255\n",
      "56\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "3092 Pandas(Index=3092, Filename='002659.jpg', Age=26.95833396911621, Std=5.556371688842773, Age_category=1)\n",
      "3092 (720, 652)\n",
      "255\n",
      "0\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "3285 Pandas(Index=3285, Filename='002013.jpg', Age=20.156862258911133, Std=2.767971992492676, Age_category=0)\n",
      "3285 (250, 400)\n",
      "205\n",
      "3\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "3408 Pandas(Index=3408, Filename='002077.jpg', Age=26.710525512695312, Std=6.00398063659668, Age_category=1)\n",
      "3408 (166, 166)\n",
      "255\n",
      "22\n",
      "--------------------------------------------------\n",
      "-----Write Error----------------------------------\n",
      "3408 Pandas(Index=3408, Filename='002077.jpg', Age=26.710525512695312, Std=6.00398063659668, Age_category=1)\n",
      "Faces/1/3408002077.png\n",
      "(0, 0)\n",
      "--------------------------------------------------\n",
      "3481 Pandas(Index=3481, Filename='003090.jpg', Age=37.46154022216797, Std=8.228611946105957, Age_category=2)\n",
      "3481 (645, 497)\n",
      "234\n",
      "10\n",
      "--------------------------------------------------\n",
      "-----Write Error----------------------------------\n",
      "3481 Pandas(Index=3481, Filename='003090.jpg', Age=37.46154022216797, Std=8.228611946105957, Age_category=2)\n",
      "Faces/2/3481003090.png\n",
      "(377, 0)\n"
     ]
    }
   ],
   "source": [
    "for ir in labels_adults.itertuples():\n",
    "    tempimage=cv2.imread(str('train/'+ ir[1]),cv2.IMREAD_ANYCOLOR | cv2.IMREAD_ANYDEPTH)\n",
    "    try:\n",
    "        gray_img = cv2.cvtColor(tempimage, cv2.COLOR_BGR2GRAY)#Image is converted to gray-scale for face detection\n",
    "    except: ## Discard image if it is already grayscale\n",
    "        print(str('--------------------------------------------------'))\n",
    "        print(str(ir[0])+' '+str(ir))\n",
    "        print(str(ir[0])+' '+str(tempimage.shape))\n",
    "        print(tempimage.max())\n",
    "        print(tempimage.min())\n",
    "        print(str('--------------------------------------------------'))\n",
    "\n",
    "    faces = faceCascade.detectMultiScale(gray_img,scaleFactor=1.1,minNeighbors=5,flags=cv2.CASCADE_SCALE_IMAGE)\n",
    "    #print(type(faces))\n",
    "    if( isinstance(faces,tuple)):\n",
    "        if(len(faces)==0):\n",
    "            continue ## No Faces detected\n",
    "        else:\n",
    "            maxA=0\n",
    "            face1=tempimage[faces[1]:faces[1]+faces[3],faces[0]:faces[0]+faces[2]]\n",
    "    else:\n",
    "        maxA = np.apply_along_axis(calcarea,1,faces).argmax()\n",
    "        face1=tempimage[faces[maxA][1]:faces[maxA][1]+faces[maxA][3],faces[maxA][0]:faces[maxA][0]+faces[maxA][2]]\n",
    "    filename=str('Faces/'+str(ir[4])+'/' +str(int(ir[0]))+ str(ir[1][0:-4]) + '.png' )\n",
    "    try:\n",
    "        cv2.imwrite(filename,face1)\n",
    "    except:\n",
    "        print(str('-----Write Error----------------------------------'))\n",
    "        print(str(ir[0])+' '+str(ir))\n",
    "        print(filename)\n",
    "        print(face1.shape)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Repeating the same steps on validation data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4112 entries, 0 to 4111\n",
      "Data columns (total 3 columns):\n",
      "Filename    4112 non-null object\n",
      "Age         4112 non-null float32\n",
      "Std         4112 non-null float32\n",
      "dtypes: float32(2), object(1)\n",
      "memory usage: 64.4+ KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f9405defcc0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "valid_labels=pd.read_csv('valid_gt.csv',sep=',',header=1,names=['Filename','Age','Std'], dtype={'Filename':str , 'Age':np.float32 , 'Std':np.float32 }  )\n",
    "#labels['Age_category'],agebins=pd.qcut(labels['Age'],3,labels=False,retbins=True)\n",
    "print(labels.info())\n",
    "valid_labels['Age'].hist(bins=np.arange(0,90,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/prasadb/miniconda3/envs/tf-graphViz/lib/python3.6/site-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "valid_labels_adults=valid_labels.loc[valid_labels['Age']>18.0]\n",
    "\n",
    "def sort_valid_labels(row):\n",
    "    if row['Age']<agebins[1]:\n",
    "        return 0\n",
    "    elif (row['Age']>= agebins[1]) and (row['Age']<agebins[2]):\n",
    "        return 1\n",
    "    elif (row['Age']>=agebins[2]):\n",
    "        return 2\n",
    "\n",
    "valid_labels_adults['Age_category']=valid_labels_adults.apply(sort_valid_labels,1)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>Age</th>\n",
       "      <th>Std</th>\n",
       "      <th>Age_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>004519.jpg</td>\n",
       "      <td>31.394737</td>\n",
       "      <td>5.598588</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>004997.jpg</td>\n",
       "      <td>39.250000</td>\n",
       "      <td>5.422341</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>004871.jpg</td>\n",
       "      <td>29.692308</td>\n",
       "      <td>5.566170</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>004839.jpg</td>\n",
       "      <td>28.117647</td>\n",
       "      <td>3.797043</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>004180.jpg</td>\n",
       "      <td>23.739130</td>\n",
       "      <td>2.591246</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Filename        Age       Std  Age_category\n",
       "1  004519.jpg  31.394737  5.598588             1\n",
       "2  004997.jpg  39.250000  5.422341             2\n",
       "3  004871.jpg  29.692308  5.566170             1\n",
       "4  004839.jpg  28.117647  3.797043             1\n",
       "5  004180.jpg  23.739130  2.591246             0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_labels_adults.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir valid_Faces\n",
    "!mkdir valid_Faces/0\n",
    "!mkdir valid_Faces/1\n",
    "!mkdir valid_Faces/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "247 Pandas(Index=247, Filename='004503.jpg', Age=21.365385055541992, Std=4.146494388580322, Age_category=0)\n",
      "247 (223, 144)\n",
      "255\n",
      "0\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "753 Pandas(Index=753, Filename='004645.jpg', Age=43.54999923706055, Std=7.813290119171143, Age_category=2)\n",
      "753 (679, 523)\n",
      "255\n",
      "0\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for ir in valid_labels_adults.itertuples():\n",
    "    tempimage=cv2.imread(str('valid/'+ ir[1]),cv2.IMREAD_ANYCOLOR | cv2.IMREAD_ANYDEPTH)\n",
    "    try:\n",
    "        gray_img = cv2.cvtColor(tempimage, cv2.COLOR_BGR2GRAY)#Image is converted to gray-scale for face detection\n",
    "    except: ## Discard image if it is already grayscale\n",
    "        print(str('--------------------------------------------------'))\n",
    "        print(str(ir[0])+' '+str(ir))\n",
    "        print(str(ir[0])+' '+str(tempimage.shape))\n",
    "        print(tempimage.max())\n",
    "        print(tempimage.min())\n",
    "        print(str('--------------------------------------------------'))\n",
    "\n",
    "    faces = faceCascade.detectMultiScale(gray_img,scaleFactor=1.1,minNeighbors=5,flags=cv2.CASCADE_SCALE_IMAGE)\n",
    "    #print(type(faces))\n",
    "    if( isinstance(faces,tuple)):\n",
    "        if(len(faces)==0):\n",
    "            continue ## No Faces detected\n",
    "        else:\n",
    "            maxA=0\n",
    "            face1=tempimage[faces[1]:faces[1]+faces[3],faces[0]:faces[0]+faces[2]]\n",
    "    else:\n",
    "        maxA = np.apply_along_axis(calcarea,1,faces).argmax()\n",
    "        face1=tempimage[faces[maxA][1]:faces[maxA][1]+faces[maxA][3],faces[maxA][0]:faces[maxA][0]+faces[maxA][2]]\n",
    "    filename=str('valid_Faces/'+str(ir[4])+'/' +str(int(ir[0]))+ str(ir[1][0:-4]) + '.png' )\n",
    "    try:\n",
    "        cv2.imwrite(filename,face1)\n",
    "    except:\n",
    "        print(str('-----Write Error----------------------------------'))\n",
    "        print(str(ir[0])+' '+str(ir))\n",
    "        print(filename)\n",
    "        print(face1.shape)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder 0 \n",
      "No. of Files: 1006\n",
      "Folder 1 \n",
      "No. of Files: 1038\n",
      "Folder 2 \n",
      "No. of Files: 1058\n"
     ]
    }
   ],
   "source": [
    "!for i in `seq 0 2` ; do echo -n \"Folder ${i} \\nNo. of Files: \" ; ls Faces/${i}/ | wc -l ; done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
